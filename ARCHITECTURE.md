# ğŸ—ï¸ Architecture - job-finder

**×ª××¨×™×š:** 21 ××•×§×˜×•×‘×¨ 2025
**×’×¨×¡×”:** 1.0

---

## ğŸ¯ ××˜×¨×ª ×”×¤×¨×•×™×§×˜

××¢×¨×›×ª **multi-agent** ×¤×©×•×˜×” ×•×‘×¨×•×¨×” ×œ××¦×™××ª ××©×¨×•×ª, ×©××©×œ×‘×ª:
- × ×™×ª×•×— ×§×•×¨×•×ª ×—×™×™× ×—×›×
- ×—×™×¤×•×© ××©×¨×•×ª ×‘×–××Ÿ ×××ª
- ××™×“×¢ ×¢×œ ×—×‘×¨×•×ª ××¤×•×¨×•××™× (Reddit) ×•×—×“×©×•×ª
- ×”×ª×××” ×—×›××” ×‘×™×Ÿ ×”××©×¨×•×ª ×œ×§×•×¨×•×ª ×”×—×™×™×

**×”×¢×™×§×¨×•×Ÿ:** ×›×œ agent ×¢×•×©×” ×“×‘×¨ ××—×“ ×˜×•×‘, ×”-pipeline ××—×‘×¨ ××•×ª×.

---

## ğŸ¤– 4 Agents - ×ª×™××•×¨ ××¤×•×¨×˜

### Agent 1: CV Analyzer ğŸ“„

**×ª×¤×§×™×“:** ×× ×ª×— ×§×•×¨×•×ª ×—×™×™× ×•××•×¦×™× ××™×“×¢ ××•×‘× ×”

**Input:**
- ×§×•×‘×¥ PDF/Text ×©×œ ×§×•×¨×•×ª ×—×™×™×

**Process:**
1. ×§×¨×™××ª ×”×§×•×‘×¥ (PyPDF2)
2. × ×™×§×•×™ ×˜×§×¡×˜ (regex, NLP)
3. ×©×œ×™×—×” ×œ-OpenAI ×œ×–×™×”×•×™:
   - Skills (Python, Docker, AWS, etc.)
   - Experience level (Junior/Mid/Senior/Lead)
   - Preferred locations
   - Years of experience

**Output (Pydantic model):**
```python
class CVAnalysis(BaseModel):
    skills: List[str]
    experience_level: Literal["Junior", "Mid", "Senior", "Lead"]
    years_of_experience: int
    preferred_locations: List[str]
    key_achievements: List[str]
```

**Files:**
- `agents/cv_analyzer.py`
- `tests/test_cv_analyzer.py`

---

### Agent 2: Job Scraper ğŸ”

**×ª×¤×§×™×“:** ××—×¤×© ××©×¨×•×ª ×××ª×¨×™ ×“×¨×•×©×™×

**Input:**
- Job title (e.g., "Python Developer")
- Location (optional)
- Number of jobs to fetch (default: 20)

**Process:**
1. Scraping ×-LinkedIn Jobs / Indeed (BeautifulSoup)
2. Parsing ×©×œ:
   - Job title
   - Company name
   - Location
   - Job description
   - Application URL
3. × ×™×§×•×™ ×•× ×¨××•×œ ×©×œ ×”× ×ª×•× ×™×

**Output (Pydantic model):**
```python
class Job(BaseModel):
    title: str
    company: str
    location: str
    description: str
    url: str
    posted_date: Optional[str]
    source: Literal["linkedin", "indeed", "direct"]
```

**Files:**
- `agents/job_scraper.py`
- `tests/test_job_scraper.py`

---

### Agent 3: News & Forum Intelligence ğŸ“°

**×ª×¤×§×™×“:** ××•×¡×£ ××™×“×¢ ×¢×œ ×—×‘×¨×•×ª ××¤×•×¨×•××™× ×•×—×“×©×•×ª

**Input:**
- Company name

**Process:**
1. **Reddit scraping:**
   - ×—×™×¤×•×© ×‘subreddits ×¨×œ×•×•× ×˜×™×™× (/r/cscareerquestions, /r/experienceddevs)
   - ××™×¡×•×£ posts ×¢×œ ×”×—×‘×¨×”
   - Sentiment analysis (×—×™×•×‘×™/×©×œ×™×œ×™)

2. **News scraping:**
   - ×—×“×©×•×ª ×¢×“×›× ×™×•×ª ×¢×œ ×”×—×‘×¨×”
   - ××™××•×Ÿ, ×¦××™×—×”, ×©×™× ×•×™×™× × ×™×”×•×œ×™×™×

**Output (Pydantic model):**
```python
class CompanyInsights(BaseModel):
    company_name: str
    reddit_sentiment: Literal["positive", "neutral", "negative"]
    reddit_highlights: List[str]  # 3-5 insights ××¨×“×™×˜
    recent_news: List[str]  # 3-5 ×›×•×ª×¨×•×ª ×—×“×©×•×ª
    culture_notes: List[str]  # ×ª×¨×‘×•×ª ××¨×’×•× ×™×ª
    data_source: str
```

**Files:**
- `agents/news_agent.py`
- `tests/test_news_agent.py`

---

### Agent 4: Smart Matcher ğŸ¯

**×ª×¤×§×™×“:** ××©×•×•×” CV ×œ××©×¨×•×ª ×•× ×•×ª×Ÿ ×¦×™×•×Ÿ ×”×ª×××”

**Input:**
- CV Analysis
- List of Jobs
- Company Insights (per job)

**Process:**
1. **Embeddings:**
   - ×™×¦×™×¨×ª embedding ×œ-CV (OpenAI)
   - ×™×¦×™×¨×ª embedding ×œ×›×œ job description

2. **Similarity calculation:**
   - Cosine similarity ×‘×™×Ÿ CV ×œjob
   - ×‘×“×™×§×ª skill overlap
   - ×”×ª×××ª experience level

3. **Scoring:**
   - ×¦×™×•×Ÿ ×‘×¡×™×¡ (0-100) ×œ×¤×™ similarity
   - ×‘×•× ×•×¡/×¢×•× ×© ×œ×¤×™ company insights
   - Ranking ×©×œ ×›×œ ×”××©×¨×•×ª

**Output (Pydantic model):**
```python
class JobMatch(BaseModel):
    job: Job
    company_insights: CompanyInsights
    match_score: float  # 0-100
    skill_overlap: List[str]
    skill_gaps: List[str]
    recommendation: str  # "Strong Match", "Good Fit", "Consider", "Skip"
    reasoning: List[str]  # ×œ××” ×–×” ×”×ª×××” ×˜×•×‘×”/×œ× ×˜×•×‘×”
```

**Files:**
- `agents/matcher.py`
- `tests/test_matcher.py`

---

## ğŸ”„ Pipeline Architecture

### Stage-Based Execution

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 1: Input Processing (Parallel)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Task 1.1: CV Analysis     â†’ CV Analyzer       â”‚
â”‚  Task 1.2: Job Search      â†’ Job Scraper       â”‚
â”‚                                                 â”‚
â”‚  â±ï¸ Duration: ~5-10 seconds                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 2: Enrichment (Parallel per Job)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  For each job in Jobs:                          â”‚
â”‚    Task 2.1: Get Company Insights â†’ News Agent â”‚
â”‚                                                 â”‚
â”‚  â±ï¸ Duration: ~2-3 seconds per job (parallel)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 3: Matching (Sequential)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Task 3.1: Match & Rank â†’ Smart Matcher        â”‚
â”‚                                                 â”‚
â”‚  â±ï¸ Duration: ~3-5 seconds                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
                 Results!
```

### Pipeline Implementation

**File: `pipeline/orchestrator.py`**

```python
class JobFinderPipeline:
    """Main pipeline orchestrator"""

    async def run(self, cv_path: str, job_title: str, num_jobs: int = 20):
        # Stage 1: Parallel input processing
        cv_analysis, jobs = await asyncio.gather(
            self.cv_analyzer.analyze(cv_path),
            self.job_scraper.search(job_title, num_jobs)
        )

        # Stage 2: Parallel company insights (per job)
        insights_tasks = [
            self.news_agent.get_insights(job.company)
            for job in jobs
        ]
        all_insights = await asyncio.gather(*insights_tasks)

        # Stage 3: Matching & ranking
        matches = await self.matcher.match_and_rank(
            cv_analysis, jobs, all_insights
        )

        return matches
```

**×œ××” ×–×” ×™×¢×™×œ:**
- âœ… Stage 1 ×¨×¥ ×‘××§×‘×™×œ - ×—×•×¡×š ×–××Ÿ!
- âœ… Stage 2 ×¨×¥ ×‘××§×‘×™×œ ×¢×œ ×›×œ ×”××©×¨×•×ª
- âœ… Stage 3 ××§×‘×œ ×”×›×œ ××•×›×Ÿ ×•×¢×•×©×” ranking ××”×™×¨

---

## ğŸ“Š Data Flow

```
CV (PDF)
   â†“
[CV Analyzer] â†’ CVAnalysis
                      â†“
                      â†“ â† [Job Scraper] â†’ List[Job]
                      â†“         â†“
                      â†“    [News Agent] â†’ List[CompanyInsights]
                      â†“         â†“
                      â†“â”€â”€â”€â”€â”€â”€â”€â”€â”€â†“
                           â†“
                    [Smart Matcher]
                           â†“
                    List[JobMatch]
                    (sorted by score)
```

---

## ğŸ—‚ï¸ Models (Pydantic)

**File: `models/models.py`**

×›×œ ×”××•×“×œ×™× ×™×”×™×• ×‘-Pydantic v2 ×¢× validation:

```python
from pydantic import BaseModel, Field
from typing import List, Optional, Literal

class CVAnalysis(BaseModel):
    """Output ×©×œ CV Analyzer"""
    skills: List[str]
    experience_level: Literal["Junior", "Mid", "Senior", "Lead"]
    years_of_experience: int = Field(ge=0, le=50)
    preferred_locations: List[str] = Field(default_factory=list)
    key_achievements: List[str] = Field(default_factory=list)

class Job(BaseModel):
    """××©×¨×” ×‘×•×“×“×ª"""
    title: str
    company: str
    location: str
    description: str
    url: str
    posted_date: Optional[str] = None
    source: Literal["linkedin", "indeed", "direct"] = "direct"

class CompanyInsights(BaseModel):
    """×ª×•×‘× ×•×ª ×¢×œ ×—×‘×¨×”"""
    company_name: str
    reddit_sentiment: Literal["positive", "neutral", "negative"] = "neutral"
    reddit_highlights: List[str] = Field(default_factory=list)
    recent_news: List[str] = Field(default_factory=list)
    culture_notes: List[str] = Field(default_factory=list)
    data_source: str = "multiple"

class JobMatch(BaseModel):
    """××©×¨×” ××•×ª×××ª ×¢× ×¦×™×•×Ÿ"""
    job: Job
    company_insights: CompanyInsights
    match_score: float = Field(ge=0, le=100)
    skill_overlap: List[str] = Field(default_factory=list)
    skill_gaps: List[str] = Field(default_factory=list)
    recommendation: Literal["Strong Match", "Good Fit", "Consider", "Skip"] = "Consider"
    reasoning: List[str] = Field(default_factory=list)
```

---

## ğŸ§ª Testing Strategy

### Unit Tests (per agent)
- `test_cv_analyzer.py` - ×‘×“×™×§×ª parsing, OpenAI integration
- `test_job_scraper.py` - ×‘×“×™×§×ª scraping, error handling
- `test_news_agent.py` - ×‘×“×™×§×ª Reddit API, sentiment analysis
- `test_matcher.py` - ×‘×“×™×§×ª scoring logic

### Integration Tests
- `test_pipeline.py` - end-to-end pipeline test

### ××” × ×‘×“×•×§:
- âœ… Valid inputs â†’ valid outputs
- âœ… Invalid inputs â†’ proper errors
- âœ… Edge cases (empty CV, no jobs found, etc.)
- âœ… Mocking ×©×œ API calls (OpenAI, Reddit)

---

## ğŸ” Environment Variables

**File: `.env.example`**

```bash
# OpenAI
OPENAI_API_KEY=sk-your-key-here

# Reddit API (create app at reddit.com/prefs/apps)
REDDIT_CLIENT_ID=your-client-id
REDDIT_CLIENT_SECRET=your-client-secret
REDDIT_USER_AGENT=job-finder/1.0

# Optional: News API
NEWS_API_KEY=your-news-api-key
```

---

## ğŸ“¦ Dependencies

**File: `requirements.txt`**

```
# Core
pydantic>=2.7.0
python-dotenv>=1.0.0

# PDF Processing
PyPDF2>=3.0.0

# Web Scraping
beautifulsoup4>=4.12.0
requests>=2.31.0
selenium>=4.0.0  # If needed for dynamic content

# Reddit
praw>=7.7.0

# OpenAI
openai>=1.40.0

# Async
aiohttp>=3.9.0

# Testing
pytest>=8.0.0
pytest-asyncio>=0.23.0
pytest-mock>=3.12.0

# Utilities
numpy>=1.26.0
scikit-learn>=1.4.0  # For cosine similarity
```

---

## ğŸš€ Usage Example

```python
from pipeline.orchestrator import JobFinderPipeline

# Initialize pipeline
pipeline = JobFinderPipeline()

# Run
matches = await pipeline.run(
    cv_path="examples/my_cv.pdf",
    job_title="Python Developer",
    num_jobs=20
)

# Print top 5 matches
for match in matches[:5]:
    print(f"{match.job.title} at {match.job.company}")
    print(f"Score: {match.match_score}/100")
    print(f"Recommendation: {match.recommendation}")
    print(f"Reasoning: {', '.join(match.reasoning)}")
    print("---")
```

---

## ğŸ“ˆ Future Improvements (V2)

×× × ×¨×¦×” ×œ×”×¨×—×™×‘ ×‘×¢×ª×™×“:
- ğŸ”„ Celery/Redis ×œqueue ×©×œ tasks
- ğŸ’¾ Database (PostgreSQL) ×œ×©××™×¨×ª results
- ğŸŒ FastAPI endpoint ×œ-REST API
- ğŸ“§ Email notifications
- ğŸ“Š Dashboard (Streamlit)
- ğŸ¤– More agents (Salary predictor, Interview prep)

**××‘×œ ×œ× ×¢×›×©×™×•! V1 = ×¤×©×•×˜ ×•×¢×•×‘×“.**

---

## ğŸ“ Learning Goals

××” ××ª×” ×ª×œ××“ ×‘×¤×¨×•×™×§×˜ ×”×–×”:
- âœ… Multi-agent architecture
- âœ… Async/await programming
- âœ… Pydantic models & validation
- âœ… Web scraping (BeautifulSoup)
- âœ… Reddit API (PRAW)
- âœ… OpenAI API (embeddings, chat)
- âœ… Testing best practices
- âœ… Clean code structure

**×–×” ×”×¤×¨×•×™×§×˜ ×©×ª×¨××” ×œ-recruiters!** ğŸ¯

---

**×¢×“×›×•×Ÿ ××—×¨×•×Ÿ:** 21 ××•×§×˜×•×‘×¨ 2025
